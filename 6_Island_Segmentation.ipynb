{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93696bef",
   "metadata": {},
   "source": [
    "# Part 6: Segmentation with new orthophotos\n",
    "\n",
    "Within this notebook, the previously trained model for pedestrian refuge island segmentation can be further used on new aerial images. In the end, the predicted coordinates of the objects are again stored in a geoJSON and are ready for comparison.\n",
    "\n",
    "Precondition for this part:\n",
    "- The TIF images must be tagged with the Spherical Mercator projection coordinates. Otherwise, the coordinates will be invalid. Alternatively, one can manually change the EPSG Code in the transformer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rasterio as rio\n",
    "import cv2\n",
    "import tifffile\n",
    "from fastai.vision.all import *\n",
    "from geojson import Feature, Point, FeatureCollection, dump\n",
    "from skimage import io, exposure\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgba2rgb\n",
    "from skimage.util import img_as_ubyte\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e22c22",
   "metadata": {},
   "source": [
    "#### Paths, Directories and Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803d0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = Path(os.getcwd()) \n",
    "DATASET_PATH = CURRENT_PATH / \"data\"\n",
    "IMAGES_PATH = DATASET_PATH / 'islands'\n",
    "PRED_MASK_PATH = DATASET_PATH / 'pred_mask'\n",
    "PRED_MASK_PATH_TFMS = DATASET_PATH / 'pred_mask_tfms'\n",
    "\n",
    "# Create Directory\n",
    "if not DATASET_PATH.exists():\n",
    "    os.mkdir(DATASET_PATH)\n",
    "    os.mkdir(IMAGES_PATH)\n",
    "    os.mkdir(PRED_MASK_PATH)\n",
    "    os.mkdir(PRED_MASK_PATH_TFMS)\n",
    "    print('Directories created!')\n",
    "# Download exporter\n",
    "if not CURRENT_PATH.ls(file_exts='.pkl'):\n",
    "    urllib.request.urlretrieve(url=r'https://drive.switch.ch/index.php/s/9W2w1m5k0mENn7F/download',filename=CURRENT_PATH/'island_segmentation_resnet18.pkl') \n",
    "    print('Learner downloaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f82b6a",
   "metadata": {},
   "source": [
    "#### 6 Steps From Orthophoto (TIFF) to GeoJSON\n",
    "\n",
    "1. Provide Images as TIFF into directory: _/PT1-Refuge_Islands/data/islands\n",
    "2. TIFF (with Spherical Mercator projection coordinates) converted into PNG\n",
    "3. Lernear imported and set up \n",
    "4. Masks predicted\n",
    "5. Adjusted mask size\n",
    "6. Coordinates maped, extracted and saved as GeoJSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Convert provided images from TIFF to PNG\n",
    "\n",
    "def read_image(img, channels=None):\n",
    "    with tifffile.TiffFile(img) as tif:\n",
    "        im = tif.asarray()\n",
    "    if channels:\n",
    "        im = im[:, :, channels]\n",
    "    return im\n",
    "\n",
    "def reduce_image_array(i_array):\n",
    "    image = i_array/i_array.max()\n",
    "    image = img_as_ubyte(image)\n",
    "    return image\n",
    "\n",
    "def save_img_as_png(im_file, dest_folder, channels=[2,1,0]):\n",
    "    file_out = dest_folder / f\"{im_file.stem}.png\"\n",
    "    im = read_image(im_file, channels=channels)\n",
    "    im = reduce_image_array(im)\n",
    "    io.imsave(file_out.absolute(), im)\n",
    "    return file_out\n",
    "\n",
    "def split_list(l, number_of_parts):\n",
    "    splitted = np.array(np.array_split(l, number_of_parts), dtype=object)\n",
    "    return [s.tolist() for s in splitted]\n",
    "\n",
    "def convert_list_of_images(image_list, out_folder):\n",
    "    for im_path in image_list:\n",
    "        save_img_as_png(im_path, out_folder)\n",
    "\n",
    "        \n",
    "# Verify tif exist\n",
    "if any(list((IMAGES_PATH.glob(\"*.tif\")))):    \n",
    "\n",
    "    # Create png folder\n",
    "    IMAGES_PNG_PATH = DATASET_PATH / 'images_png'\n",
    "    if not IMAGES_PNG_PATH.exists():\n",
    "        os.mkdir(IMAGES_PNG_PATH)\n",
    "    else:\n",
    "        usr_input = input('PNG folder already existis. Delete? (Y/N): ').upper()\n",
    "        if usr_input == ('Y'):\n",
    "            shutil.rmtree(IMAGES_PNG_PATH)\n",
    "            os.mkdir(IMAGES_PNG_PATH)  \n",
    "        else:\n",
    "            exit()\n",
    "\n",
    "    number_of_parallelism = 10\n",
    "\n",
    "    # Get images in a list []\n",
    "    image_list = list(IMAGES_PATH.glob(\"*.tif\"))\n",
    "\n",
    "    # Split list into n sublist [[][]]\n",
    "    image_list_splitted = split_list(image_list, number_of_parallelism)\n",
    "\n",
    "    do_conversion = partial(convert_list_of_images, out_folder=IMAGES_PNG_PATH)\n",
    "\n",
    "    with Pool(number_of_parallelism) as p:\n",
    "        p.map(do_conversion, image_list_splitted)\n",
    "    print('Images converted!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Import and set up learner\n",
    "\n",
    "# Metric\n",
    "def calc_accuracy(inp, targ):\n",
    "  targ = targ.squeeze(1)\n",
    "  mask = targ == 255\n",
    "  return (inp.argmax(dim=1)[mask]==targ[mask]).float().mean()\n",
    "\n",
    "# Label\n",
    "def label_func(fn):\n",
    "    return TEST_MASKS_PATH / f\"{fn.stem}.png\"\n",
    "\n",
    "\n",
    "# Codes\n",
    "codes = 255 * [\"not_island\"]\n",
    "codes.append('island')\n",
    "\n",
    "# Image Augmentation\n",
    "batch_tfms = aug_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)\n",
    "\n",
    "# Learner\n",
    "learner = load_learner(Path('island_segmentation_resnet18.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8d7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Predict Masks based on PNG's\n",
    "\n",
    "def pred_mask():\n",
    "    cnt = 1\n",
    "    print('Prediction started..')\n",
    "    for img in IMAGES_PNG_PATH.ls():\n",
    "\n",
    "        # Predict mask based on original test image\n",
    "        pred_msk_array, pred_idx, outputs = learner.predict(item=img)\n",
    "\n",
    "        # Save predicted mask\n",
    "        pred_msk = PRED_MASK_PATH/ ('pred_'+ img.name)\n",
    "        pred_mask_img = PILMask.create(pred_msk_array)\n",
    "        pred_mask_img.save(pred_msk, format=\"png\")\n",
    "        \n",
    "        print('item ' + str(cnt) + '/' + str(len(IMAGES_PNG_PATH.ls())))\n",
    "        cnt +=1\n",
    "        \n",
    "pred_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096718e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Align size of predicted Masks\n",
    "\n",
    "def get_original_shape(item_name,org_dir):    \n",
    "    for img in IMAGES_PATH.iterdir():\n",
    "        if item_name == img.stem:\n",
    "            with rio.open(img) as dataset: \n",
    "                return dataset.shape\n",
    "\n",
    "def resize_items(item,x,y): \n",
    "    resize_item = item.resize(torch.Size([x, y]))\n",
    "    return resize_item\n",
    "\n",
    "def threshold_item(item):\n",
    "    \"Convert all values between 0 and 255 to either 0 or 255\"\n",
    "    pred_msk_array_resized = array(item)\n",
    "    return PILImage.create(pred_msk_array_resized.clip(0, 1).astype(\"uint8\") * 255)\n",
    "\n",
    "def verify_shape_size(resized_pred_dir,org_dir):\n",
    "    print('Verifying shape sizes...')\n",
    "    all_match = True\n",
    "    for cnt,resized_msk in enumerate(PRED_MASK_PATH_TFMS.ls()):  \n",
    "        for original_img in IMAGES_PATH.ls():           \n",
    "            if resized_msk.stem[5:] == original_img.stem:\n",
    "                resized_pred_msk_img = Image.open(resized_msk)    \n",
    "                with rio.open(original_img) as dataset: \n",
    "                    if dataset.shape != resized_pred_msk_img.shape:\n",
    "                        print(cnt, 'ATTENTION NOT SAME SHAPE!')\n",
    "                        print('Resized predicted Mask: ', resized_msk.name, '  Shape: ', resized_pred_msk_img.shape)\n",
    "                        print('Original Image: ', original_img.name, '  Shape: ', resized_pred_msk_img.shape, '\\n')\n",
    "                        all_match = False  \n",
    "\n",
    "    if all_match:\n",
    "        print('All shapes match!')  \n",
    "\n",
    "\n",
    "def align_pred_to_original_shape(pred_dir, org_dir, resized_pred_dir_out):\n",
    "    \n",
    "    # Check directory\n",
    "    if not PRED_MASK_PATH_TFMS.exists():\n",
    "        os.mkdir(PRED_MASK_PATH_TFMS)\n",
    "    \n",
    "    print('Resizing predicted mask..')\n",
    "    \n",
    "    # Align pred mask shape with original image shape and save mask into new folder\n",
    "    for pred_msk in PRED_MASK_PATH.ls():\n",
    "        pred_msk_img = Image.open(pred_msk)          \n",
    "        org_img_shape = get_original_shape(pred_msk.stem[5:],org_dir)\n",
    "        pred_msk_img_resized= resize_items(item=pred_msk_img,x=org_img_shape[1],y=org_img_shape[0])\n",
    "        pred_msk_img_resized_threshold=threshold_item(item=pred_msk_img_resized)\n",
    "        pred_msk_img_resized_threshold.save(resized_pred_dir_out/pred_msk.name)\n",
    "\n",
    "    verify_shape_size(resized_pred_dir_out,org_dir)\n",
    "\n",
    "align_pred_to_original_shape(PRED_MASK_PATH,IMAGES_PATH,PRED_MASK_PATH_TFMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42915b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Map and extract coordinates into GeoJSON\n",
    "\n",
    "def get_pixel_coordinates(pred_mask):\n",
    "    crossings = list()\n",
    "    \n",
    "    # Convert Mask into 2dimensional array    \n",
    "    gray_image = cv2.cvtColor(cv2.imread(str(pred_mask)) , cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, hierarchy = cv2.findContours(image=gray_image,mode=cv2.RETR_TREE,method=cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for i,c in enumerate(contours):\n",
    "        \n",
    "        if cv2.contourArea(c) > 210: # Exclude small marks    \n",
    "            crossing = np.zeros(gray_image.shape[:2], np.uint8)\n",
    "            cv2.drawContours(crossing, [c], -1, (255), -1)\n",
    "            loc, dims, angle = cv2.minAreaRect(c) \n",
    "    \n",
    "            # Calculate moments for each contour\n",
    "            M = cv2.moments(c)\n",
    "            \n",
    "            # Calculate x,y coordinate of center\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])           \n",
    "            \n",
    "            crossings.append([cX,cY])\n",
    "    \n",
    "    return crossings\n",
    "\n",
    "\n",
    "def get_real_coordinates(data):    \n",
    "    x,y = convert_coordinates(data[0][0],data[0][1])        \n",
    "    return x,y\n",
    "\n",
    "\n",
    "def convert_coordinates(x,y):\n",
    "    \"\"\"\n",
    "    EPSG:3857 --> Spherical Mercator projection coordinate \n",
    "    EPSG:4326 --> WGS84 \n",
    "    \"\"\"\n",
    "    points = [(x,y)]\n",
    "    transformer = Transformer.from_crs(3857, 4326)\n",
    "    for pt in transformer.itransform(points): \n",
    "        return pt\n",
    "    \n",
    "    \n",
    "def get_geo_json(coordinates):    \n",
    "    \"Taskes List with tuple coordinates and creates a geojson\"   \n",
    "    \n",
    "    feature_list = list()\n",
    "    \n",
    "    for x,y in coordinates:\n",
    "        feature_list.append(Feature(geometry=Point((y, x))))\n",
    "  \n",
    "    feature_collection = FeatureCollection(feature_list)\n",
    "    \n",
    "    return feature_collection\n",
    "                      \n",
    "    \n",
    "\n",
    "def main():\n",
    "    cnt = 1\n",
    "    real_coordinates = list()\n",
    "    print('Mappingprocess started..')\n",
    "    \n",
    "    # Get mask and real image\n",
    "    for cnt,resized_msk in enumerate(PRED_MASK_PATH_TFMS.ls()):        \n",
    "        for original_img in IMAGES_PATH.ls():           \n",
    "            if resized_msk.stem[5:] == original_img.stem:\n",
    "                with rio.open(original_img) as dataset: \n",
    "                    \n",
    "                    # Get pixel coordinates \n",
    "                    crossings = get_pixel_coordinates(resized_msk)\n",
    "                    \n",
    "                    for crossing in crossings:\n",
    "                        cX,cY = crossing\n",
    "                        val = dataset.read(4)\n",
    "                        no_data=dataset.nodata  \n",
    "                        if val[cX,cY] != no_data:\n",
    "                            data = [(dataset.xy(cY,cX)[0],dataset.xy(cY,cX)[1],val[cY,cX])]\n",
    "                            real_coordinates.append((get_real_coordinates(data)))\n",
    "        print('item ' + str(cnt) + '/' + str(len(PRED_MASK_PATH_TFMS.ls())))\n",
    "        cnt +=1\n",
    "    geo_json = get_geo_json(real_coordinates)\n",
    "    \n",
    "    with open('island_coordinates.geojson','w') as f:\n",
    "        dump(geo_json,f)\n",
    "\n",
    "    return geo_json\n",
    "    \n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
